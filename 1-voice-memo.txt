 Alright, I'm walking home from the grocery store and thinking out loud and brainstorming about doing a hackathon talk thing later this week. And trying to give a brief tour de force of a bunch of interesting things you can do with language models that might incorporate into people's workflows, sort of using AI to accelerate working on alignment work. So of course I have the front of the method that I use, which is to record these voice memos. While I'm just walking around. They're disorganized, I lose track of topics and threads and post-processing them is a bit of a chore. But yeah, so let's say the first thing I want to demo is speech to text with whisper. That's sort of boring, I don't expect it to be at all interesting. So that goes from an audio file to a text transcript. And sort of the second thing I want to demo is the text organization stuff I have with these transcripts. So that's going to be, let's just say there's three things there. The first one is title processing. The second one is summary and key points processing. And the third one is extracting to-do items. And it would be good to have a demo that includes something where the text is too long to process, so you have to process these in multiple bits. So maybe that's the next thing I will demo after the three processing steps on their own will be the processing steps on multi-chunk data. So that will include, let's just say that includes two versions. One is the sort of parallel version, where there's a bunch of separate reductions on all the parts, and then you do a final reduction on the results of those. And the second one is the sort of rolling reduction. These could be analogous to a linear versus a tree based reductive arithmetic operation. But the rolling is going to be the summary, where you include the summary of the overall document or summary of the previous section as you summarize the current section. And so you have to roll through everything. So that gets us our notes. And then, what do we do with them? Maybe the next thing I might want to demo is sort of structured creativity ideation. So this could look like, let's demo a specific structured creativity exercise, which is big lists, using the generating big lists of things. Maybe I'll do the generate a big list of things to demo in this talk, which is like ways you can use language models to accelerate research. And maybe one of the things I can boggle there is sort of like a big list of what are all the individual things that a researcher has to do. And then for each one, what is one way that advanced language model AI could help it. So yeah, this bit is both demoing the participatory big list method, as well as the going over a big list method in a super fast way with something like a playground. So after that, maybe I want to think a little bit more in depth about a couple of the specific things and going to like rubber ducking with, let's say with a chatbot, but also have a demo that is doable both with the chatbot and with the generic model, which you can prompt into being a chatbot. Let's say one of the things I want to do is explain my plan. I'm going to give this talk. It's to these people. What are some things I should cover? What are some potential pitfalls? What are ways in which the talk could go wrong? And how should I prepare for them? What are people most likely to take away from the talk? What are people most likely going to miss? And can I use those to change the shape of the talk to be better fit to what people will like recall? Maybe what would people actually use? And how could I deliver something that they can sort of tinker with on their own, as opposed to this just being a lecture? So yeah, that demo of the rubber ducking chat session is with a model, either in a chat modality or a chat-specific model. And so now I know a little bit more about what I'm doing with these things. Now let's say I'm getting to writing the talk itself. I'm going to next demo a bunch of ways of trying and tinkering stuff with, let's say writing an outline of the talk. Having settled in on, let's make a little Jupyter notebook that people can copy. And the talk is going through the Jupyter notebook. What's the basic gist of the operations I'm going to show and the order I'm going to show them in? And so maybe I'm doing things like copying and pasting some stuff in and then asking it to generate an outline. Or maybe I'm just sort of asking it to generate an outline without the context of the other stuff and seeing what it says and there's some copying and pasting and editing and eventually let's say I have some assemblage of things that I think is good enough. I just want to go on and write my own outline or have some editing and copy pasting of that. And now I've got a basic outline. Now I can go in and the next demo is demoing Copilot. So maybe the first thing is showing Copilot in the Jupyter interactive mode in VS Code. And so what I end up doing in that demo is sort of dumping the outline in the beginning and then starting to write the individual cells. And maybe demo the difference between writing code that has lots of comments versus code that doesn't. And then finally the demo of the cadence I use, which is a natural language comment and then a generated line of code, a natural language comment and a generated line of code. Noted that this is not, the thing I'm not doing is documenting the code and if you read sort of programming style manuals they'll say just like having one line of comment for every line of code that just says exactly what the line of code does is like not actually good commenting. And I agree. But what I'm doing is I'm steering code generation at Engine in ways that I don't have to pay as close attention to syntax or the exact spelling of things or exactly what the name of a particular library function is. And it's imperfect and you'll have to debug and diagnose things. And so maybe another thing I'll show is sort of iteration. Things won't work right on the first try. You'll have to tinker with things a little bit in order to get them to work properly. So yeah, maybe I want to talk about another demo but I think it probably should go earlier in the sort of outline. And that's a filter demo where we use some natural language filter and a few shot prompt in order to process down the list of items. So maybe this is part of or a follow on to the big list structured creativity exercises. And this is going to let us do things like when we want to do the second step of for each item do some processing, we'll have a little bit of a filter here. So the basic gist of it is we make a few shot classifier. You know, the easiest version of this is a binary classifier. And then we look at the normalized probabilities of the two classes and we set some threshold on that. Now you probably want some balance between the two classes. For example, not having five of one and one of the other. And the other things you want them to do is you want them to be mixed and not obviously ordered so not true false true false true false and not true true true false false false. So yeah. That's the filter, the natural language filter model. Maybe another demo after that is a DIY version of critique and revise. So for each thing you want to really process, maybe you have it generate some critiques of it and then maybe pick the best critique and then you revise it based on that critique. And this probably should be doable, prompt hacking in a Jupyter notebook, but maybe I'll take this as a to-do is to set up the helper functions to do things I want to do already so I can just copy and paste this helper functions in or start with them in the file instead of having to figure them out on the fly in the middle of the talk. So yeah. There's maybe one more thing that would be interesting to demo, which is embeddings and using them for similarity. Maybe doing other things with embedding space. Yeah I'm thinking about what I want to do about that. I think it's a very useful tool, but it's sort of limited in its utility because you're both dealing with a limited sort of version of the information. It's like necessarily lost a lot in the compression and also the dimensions of salience in the model or the dimensions that it captures might not be the dimensions you want to use and the metric of the space might not be natural in terms of there's a bunch of disintuitive either nearness or farness parts of the metric. And finally, whatever salient features you're looking for might be non-monotonic where most of the methods based on these are assuming some projected dimension, whether that's a direction or something else. So it's potential that you could do something like k-nearest neighbors, but I haven't personally done that, so I don't want to make that part of this demo. I mostly want to just show off stuff I actually use. Other miscellaneous things to demo. I think in general for relational or data that's related to other data, I'm going to call that relational data. For example, a last-run comment and the number of upvotes it gets, or the number of upvotes it gets as a fraction of the number of upvotes the top-level article gets, etc. And the nice thing about these autoregressive models is that you can use whatever you want as either a condition or an output. So you can do things like a bunch of few-shot examples of hero last-run comments and their scores, or here's a bunch of scores and last-run comments, and then you give it a score and then it tries to generate a comment of that score. Or you can do the opposite, where you have a bunch of comments followed by scores, and then you give it a draft of a comment and it gives you a score. So there's a way in which any relationship in the data space, where I might draw out a graph of how things are related to each other, can be inverted. And sometimes these inverses of connections let you more easily generate or manipulate the data you want to do. The more I think about it, the more this is better drawn on a whiteboard. So maybe I will figure out a way to do that. Or I can just pre-draw the drawings and inject them into the Jupyter notebook. Alright, well, maybe there's another tutu to figure out how to present the type theory interpretation of relationships and their inversions. And with that, I think I am mostly done with this brainstorming. I'm almost home with my groceries from the grocery store. I'm going to use my last two minutes to figure out if there's anything else I want to talk about in there. Maybe some more asides, and I want to gather up all the asides and the demos separately in this. So an aside is, working with language models is very different than working with normal software functions in terms of it's not exactly clear what they're doing, they're sometimes stochastic, it's not always clear ahead of time whether an idea you have can be made real or not. And it's good to be patient to understand that there will be a lot of times where you come up with something and then fail to make it. But that this is one of the best ways you can develop your understanding and aesthetic about what can or can't be built with current tools and methods, as well as what will be possible with slight improvements very soon. Hello! How's it going?
